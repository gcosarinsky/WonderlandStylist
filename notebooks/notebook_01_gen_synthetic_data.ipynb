{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f928c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 01: Synthetic Data Factory (Ollama Local)\n",
    "import ollama\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 1. cargar frases de \"Alicia en el Pa√≠s de las Maravillas\" en chunks_nltk.txt\n",
    "with open(\"../data/chunks_nltk.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texto_alicia = f.read().split(\"\\n\\n\")\n",
    "\n",
    "print(f\"Total de frases cargadas: {len(texto_alicia)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9237ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para generar el par sint√©tico\n",
    "def generar_par_sintetico(frase_original):\n",
    "    prompt = f\"\"\"\n",
    "    Eres un experto ling√ºista. Tu tarea es simplificar esta frase de Lewis Carroll \n",
    "    a un lenguaje extremadamente plano, aburrido y moderno, manteniendo el sentido:\n",
    "    \"{frase_original}\"\n",
    "    Respuesta corta, solo la frase simplificada.\n",
    "    \"\"\"\n",
    "    response = ollama.generate(model='llama3.2', prompt=prompt)\n",
    "    return response['response'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebdb7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Procesamiento con guardado incremental y recuperaci√≥n de estado\n",
    "total_frases = len(texto_alicia)\n",
    "output_file = \"../data/synthetic_alicia_ollama.jsonl\"\n",
    "checkpoint_file = \"../data/checkpoint_ollama.txt\"\n",
    "\n",
    "# Leer checkpoint si existe (√∫ltima posici√≥n procesada)\n",
    "start_index = 0\n",
    "if os.path.exists(checkpoint_file):\n",
    "    with open(checkpoint_file, \"r\") as cf:\n",
    "        start_index = int(cf.read().strip())\n",
    "    print(f\"Reanudando desde la frase {start_index + 1}\")\n",
    "\n",
    "contador = start_index\n",
    "\n",
    "# Abrir archivo en modo append si continuamos, o write si empezamos de cero\n",
    "mode = \"a\" if start_index > 0 else \"w\"\n",
    "try:\n",
    "    with open(output_file, mode, encoding=\"utf-8\") as f:\n",
    "        for i, frase in enumerate(texto_alicia[start_index:], start=start_index + 1):\n",
    "            try:\n",
    "                input_plano = generar_par_sintetico(frase)\n",
    "                entry = {\n",
    "                    \"input\": input_plano,\n",
    "                    \"output\": frase\n",
    "                }\n",
    "                # Guardar inmediatamente cada entrada\n",
    "                f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "                f.flush()  # Forzar escritura al disco\n",
    "                \n",
    "                # Actualizar checkpoint\n",
    "                with open(checkpoint_file, \"w\") as cf:\n",
    "                    cf.write(str(i))\n",
    "                \n",
    "                contador = i\n",
    "                print(f\"Procesado y guardado {i}/{total_frases} frases\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error en frase {i}: {e} - Continuando...\")\n",
    "                continue\n",
    "    \n",
    "    # Si llegamos aqu√≠, terminamos exitosamente\n",
    "    print(f\"\\n‚úÖ Total procesado y guardado: {contador} frases\")\n",
    "    # Eliminar checkpoint al finalizar\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        os.remove(checkpoint_file)\n",
    "        print(\"Checkpoint eliminado - proceso completado.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nüíæ Proceso interrumpido. √öltima frase procesada: {contador}\")\n",
    "    print(f\"Para continuar, ejecuta esta celda de nuevo.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
