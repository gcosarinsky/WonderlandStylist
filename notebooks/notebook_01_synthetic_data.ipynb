{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dda57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 01: Synthetic Data Factory\n",
    "import ollama\n",
    "import json\n",
    "\n",
    "# 1. Configuración: El libro (puedes cargar un .txt aquí)\n",
    "texto_alicia = [\n",
    "    \"¡Curioso y más curioso! —exclamó Alicia—.\",\n",
    "    \"¿De qué sirve un libro sin dibujos ni conversaciones?\",\n",
    "    \"¡Dios mío! ¡Dios mío! ¡Qué tarde voy a llegar!\"\n",
    "]\n",
    "\n",
    "def generar_par_sintetico(frase_original):\n",
    "    prompt = f\"\"\"\n",
    "    Eres un experto lingüista. Tu tarea es simplificar esta frase de Lewis Carroll \n",
    "    a un lenguaje extremadamente plano, aburrido y moderno, manteniendo el sentido:\n",
    "    \"{frase_original}\"\n",
    "    Respuesta corta, solo la frase simplificada.\n",
    "    \"\"\"\n",
    "    response = ollama.generate(model='llama3', prompt=prompt)\n",
    "    return response['response'].strip()\n",
    "\n",
    "# 2. Procesamiento\n",
    "dataset = []\n",
    "for frase in texto_alicia:\n",
    "    input_plano = generar_par_sintetico(frase)\n",
    "    dataset.append({\n",
    "        \"instruction\": \"Reescribe al estilo de Alicia en el País de las Maravillas\",\n",
    "        \"input\": input_plano,\n",
    "        \"output\": frase\n",
    "    })\n",
    "\n",
    "# 3. Guardar para el siguiente paso\n",
    "with open(\"dataset_alicia.jsonl\", \"w\") as f:\n",
    "    for entry in dataset:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"Dataset sintético creado con éxito.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
